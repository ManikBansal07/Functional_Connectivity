# -*- coding: utf-8 -*-
"""Functional Connectivity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xd5Lu53r8vbzGTH-EiL3JDRxWNtEFnHD
"""

# Install dependencies
!pip install nilearn torch torch-geometric nibabel numpy scipy matplotlib nbformat

import os
import numpy as np
import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv
import nibabel as nib
from nilearn import input_data, datasets
from scipy.stats import zscore
import matplotlib.pyplot as plt
from google.colab import files
import logging
import nbformat
import json

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# Define GCN model (assumed architecture, update if .ipynb model differs)
class GCNConnectivity(nn.Module):
    def __init__(self, num_regions, num_features, hidden_dim=64):
        super(GCNConnectivity, self).__init__()
        self.conv1 = GCNConv(num_features, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.fc = nn.Linear(hidden_dim, num_regions)

    def forward(self, x, edge_index):
        x = torch.relu(self.conv1(x, edge_index))
        x = torch.relu(self.conv2(x, edge_index))
        x = self.fc(x)
        x = torch.tanh(x)  # Map to [-1, 1]
        x = (x + x.transpose(0, 1)) / 2  # Symmetrize
        return x

def preprocess_fmri(nifti_path, corr_threshold=0.3):
    """
    Preprocess fMRI data for GCN model using Harvard-Oxford subcortical atlas.

    Args:
        nifti_path (str): Path to fMRI NIfTI file
        corr_threshold (float): Correlation threshold for initial graph

    Returns:
        features (torch.Tensor): Node features [n_regions, n_timepoints]
        edge_index (torch.Tensor): Graph edges [2, n_edges]
        num_regions (int): Number of regions
    """
    try:
        # Load fMRI data
        img = nib.load(nifti_path)
        if len(img.shape) != 4:
            raise ValueError(
                f"Invalid NIfTI dimensions: {img.shape}, expected 4D (x, y, z, t). "
                "This file appears to be 3D, which is not suitable for functional connectivity analysis. "
                "Please upload a 4D fMRI file with time series data (e.g., shape (64, 64, 35, 100)). "
                "To check your file's dimensions, run:\n"
                "```python\n"
                "import nibabel as nib\n"
                "print(nib.load('your_file.nii').shape)\n"
                "print(nib.load('your_file.nii').header)\n"
                "```\n"
                "If you don't have a 4D file, download a sample from nilearn:\n"
                "```python\n"
                "from nilearn import datasets\n"
                "data = datasets.fetch_adhd(n_subjects=1)\n"
                "nifti_path = data.func[0]\n"
                "```\n"
                "If your .ipynb model uses 3D inputs, please share the preprocessing code."
            )

        # Fetch Harvard-Oxford subcortical atlas
        atlas = datasets.fetch_atlas_harvard_oxford('sub-maxprob-thr25-2mm')
        masker = input_data.NiftiLabelsMasker(labels_img=atlas.maps, standardize=False)
        time_series = masker.fit_transform(img)

        # Normalize time series
        time_series = zscore(time_series, axis=1, ddof=1)
        time_series = np.nan_to_num(time_series, nan=0.0)

        # Create features
        num_regions, num_timepoints = time_series.shape
        if num_timepoints < 2:
            raise ValueError(f"Too few timepoints ({num_timepoints}). Functional connectivity requires multiple timepoints.")
        features = torch.tensor(time_series, dtype=torch.float)

        # Compute correlation-based adjacency
        corr_matrix = np.corrcoef(time_series)
        corr_matrix = np.nan_to_num(corr_matrix, nan=0.0)
        edge_index = np.where(np.abs(corr_matrix) > corr_threshold)
        edge_index = torch.tensor(np.array(edge_index), dtype=torch.long)

        logger.info(f"Preprocessed {nifti_path}: {num_regions} regions, {num_timepoints} timepoints")
        return features, edge_index, num_regions
    except Exception as e:
        logger.error(f"Preprocessing error: {str(e)}")
        raise

def validate_connectivity_matrix(matrix, expected_shape):
    """
    Validate connectivity matrix.

    Args:
        matrix (np.ndarray): Connectivity matrix
        expected_shape (tuple): Expected shape (n_regions, n_regions)

    Returns:
        bool: True if valid
    """
    if matrix.shape != expected_shape:
        raise ValueError(f"Invalid matrix shape: {matrix.shape}, expected {expected_shape}")
    if not np.all((matrix >= -1) & (matrix <= 1)):
        raise ValueError("Matrix values outside [-1, 1]")
    if not np.allclose(matrix, matrix.T, atol=1e-5):
        raise ValueError("Matrix is not symmetric")
    return True

def parse_ipynb_model(ipynb_path):
    """
    Parse .ipynb file to check for model definition or weights.

    Args:
        ipynb_path (str): Path to .ipynb file

    Returns:
        model (nn.Module): Model instance (untrained if no weights found)
        has_weights (bool): Whether weights were found
    """
    try:
        with open(ipynb_path, 'r', encoding='utf-8') as f:
            notebook = nbformat.read(f, as_version=4)

        model = None
        has_weights = False

        # Check code cells for model definition or weights
        for cell in notebook.cells:
            if cell.cell_type == 'code':
                code = cell.source
                # Look for model definition (simplified check)
                if 'class' in code and ('nn.Module' in code or 'GCNConv' in code):
                    logger.info("Found potential model definition in .ipynb")
                    # Assume it's compatible with GCNConnectivity for now
                    # If different, user must share code
                if 'torch.save' in code and '.pth' in code:
                    logger.info("Found code saving .pth file. Please run the .ipynb to generate it.")
                if 'state_dict' in code or 'load_state_dict' in code:
                    logger.info("Found potential weights handling code.")
                    has_weights = False  # Weights not directly usable without execution

        # Default to untrained GCNConnectivity
        # Will be updated with num_regions, num_features later
        model = GCNConnectivity(num_regions=1, num_features=1)
        logger.warning(
            f"No weights found in {ipynb_path}. Using untrained model. "
            "Please run the .ipynb to generate a .pth file with weights using:\n"
            "```python\n"
            "torch.save(model.state_dict(), 'model.pth')\n"
            "```\n"
            "Or share the model definition and weights code from the .ipynb."
        )

        return model, has_weights
    except Exception as e:
        logger.error(f"Error parsing .ipynb: {str(e)}")
        raise ValueError(
            f"Failed to parse {ipynb_path}: {str(e)}. "
            "Please run the .ipynb to generate a .pth file or share the model code."
        )

def predict_connectivity(nifti_path, ipynb_path=None):
    """
    Predict connectivity matrix using model from .ipynb.

    Args:
        nifti_path (str): Path to NIfTI file
        ipynb_path (str, optional): Path to .ipynb file

    Returns:
        dict: Connectivity matrix, metrics, heatmap
    """
    try:
        # Preprocess
        features, edge_index, num_regions = preprocess_fmri(nifti_path)

        # Load model
        if ipynb_path and os.path.exists(ipynb_path):
            model, has_weights = parse_ipynb_model(ipynb_path)
            # Update model with correct dimensions
            model = GCNConnectivity(num_regions, features.shape[1])
            if not has_weights:
                logger.warning("No pre-trained weights loaded. Results may be unreliable.")
        else:
            model = GCNConnectivity(num_regions, features.shape[1])
            logger.warning(
                f"No .ipynb provided at {ipynb_path or 'None'}. Using untrained model."
            )
        model.eval()

        # Predict
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        features = features.to(device)
        edge_index = edge_index.to(device)

        with torch.no_grad():
            connectivity = model(features, edge_index)
            connectivity = connectivity.cpu().numpy()

        # Validate
        validate_connectivity_matrix(connectivity, (num_regions, num_regions))

        # Metrics
        connectivity_flat = connectivity.flatten()
        metrics = {
            'mean': float(np.mean(connectivity_flat)),
            'std': float(np.std(connectivity_flat)),
            'max': float(np.max(connectivity_flat)),
            'min': float(np.min(connectivity_flat))
        }

        # Heatmap
        plt.figure(figsize=(8, 6))
        plt.imshow(connectivity, cmap='hot', interpolation='nearest')
        plt.colorbar(label='Connectivity Strength')
        plt.title("Functional Connectivity Matrix")
        plt.xlabel("Brain Regions")
        plt.ylabel("Brain Regions")
        plt.show()

        return {
            'connectivity_matrix': connectivity.tolist(),
            'metrics': metrics,
            'num_regions': num_regions,
            'num_timepoints': features.shape[1]
        }
    except Exception as e:
        logger.error(f"Prediction error: {str(e)}")
        raise

# Main execution
if __name__ == "__main__":
    # Upload NIfTI file
    print("Please upload your fMRI NIfTI file (.nii or .nii.gz):")
    uploaded_nifti = files.upload()
    nifti_path = next(iter(uploaded_nifti))
    with open(nifti_path, 'wb') as f:
        f.write(uploaded_nifti[nifti_path])

    # Upload .ipynb file
    print(
        "Please upload your .ipynb file (e.g., FC_Other_Models.ipynb) containing the pre-trained model. "
        "The script will attempt to parse it for model details. "
        "If weights are not found, an untrained model will be used, and you may need to share the model code."
    )
    uploaded_ipynb = files.upload()
    ipynb_path = next(iter(uploaded_ipynb))
    with open(ipynb_path, 'wb') as f:
        f.write(uploaded_ipynb[ipynb_path])

    # Predict connectivity
    print("Predicting connectivity matrix...")
    result = predict_connectivity(nifti_path, ipynb_path)

    # Display results
    print(f"Connectivity Matrix Shape: {np.array(result['connectivity_matrix']).shape}")
    print(f"Metrics: {result['metrics']}")
    print(f"Number of Regions: {result['num_regions']}")
    print(f"Number of Timepoints: {result['num_timepoints']}")